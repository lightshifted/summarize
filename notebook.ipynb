{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f69a0618",
   "metadata": {},
   "source": [
    "# GPT2 for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a15c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from minigpt.utils import set_seed\n",
    "from transformers import GPT2Tokenizer, GPT2Config, GPT2ForSequenceClassification\n",
    "\n",
    "set_seed(3407)\n",
    "\n",
    "from minigpt import bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3515212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there ...\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "import pandas as pd\n",
    "data = pd.read_csv('data/train.csv')\n",
    "text = data.full_text\n",
    "print(text[0][:200] + '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b30f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of unique chars:\n",
      " 94\n"
     ]
    }
   ],
   "source": [
    "# get vocab size\n",
    "raw_text = ''.join(data['full_text'].values.tolist())\n",
    "print('Num of unique chars:\\n', len(set(raw_text)))\n",
    "del raw_text # to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f181b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Byte Pair Encoder\n",
    "e = bpe.get_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8101db6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìê Labels:\n",
      " 0    [3.5, 3.5, 3.0, 3.0, 4.0, 3.0]\n",
      "1    [2.5, 2.5, 3.0, 2.0, 2.0, 2.5]\n",
      "2    [3.0, 3.5, 3.0, 3.0, 3.0, 2.5]\n",
      "3    [4.5, 4.5, 4.5, 4.5, 4.0, 5.0]\n",
      "4    [2.5, 3.0, 3.0, 3.0, 2.5, 2.5]\n",
      "Name: labels, dtype: object\n",
      "\n",
      "üî≠ Encoded text:\n",
      " 0    [40, 892, 326, 2444, 561, 4414, 422, 4673, 379...\n",
      "1    [2215, 257, 1917, 318, 257, 1487, 345, 423, 28...\n",
      "2    [20266, 11, 32641, 220, 1002, 334, 1487, 262, ...\n",
      "3    [464, 1266, 640, 287, 1204, 318, 618, 345, 171...\n",
      "4    [18712, 719, 286, 23887, 460, 2928, 287, 584, ...\n",
      "Name: full_text, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hedronstone\\AppData\\Local\\Temp\\ipykernel_14496\\2620102709.py:13: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  data.text_encoded = data.full_text.map(lambda x: e.encode(x))\n"
     ]
    }
   ],
   "source": [
    "# Let's organize our labels for training\n",
    "data['labels'] = list(zip(data.cohesion.tolist(), data.syntax.tolist(),\n",
    "                          data.vocabulary.tolist(), data.phraseology.tolist(),\n",
    "                          data.grammar.tolist(), data.conventions.tolist()))\n",
    "\n",
    "data.labels = data.labels.map(lambda x: list(x))\n",
    "print(f'üìê Labels:\\n {data[\"labels\"].head()}\\n')\n",
    "\n",
    "# Let's clean the text a bit\n",
    "data['full_text'] = data['full_text'].apply(lambda x: x.replace('\\n', ' '))\n",
    "\n",
    "# Now, let's encode the text using BPE class\n",
    "data.text_encoded = data.full_text.map(lambda x: e.encode(x))\n",
    "print(f'üî≠ Encoded text:\\n {data.text_encoded.head()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f3fcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "largest sequence length: 590\n",
      "smallest sequence length: 295\n"
     ]
    }
   ],
   "source": [
    "print(f'largest sequence length: {len(max(data.text_encoded))}')\n",
    "print(f'smallest sequence length: {len(min(data.text_encoded))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a3dcb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 takes a maximum of 1028 tokens. Anything above that will cause index errors.\n",
    "# So, Let's remove all samples above a given threshold\n",
    "idxs = [i for i,j in enumerate(data.text_encoded) if len(j) < 800]\n",
    "\n",
    "text = data.text_encoded[idxs].reset_index(drop=True)\n",
    "labels = data.cohesion[idxs].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88c4ec83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2799,) (2799,)\n",
      "(350,) (350,)\n",
      "(350,) (350,)\n"
     ]
    }
   ],
   "source": [
    "# Create training, validation, and test sets\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(text)\n",
    "n1 = int(0.8*len(text))\n",
    "n2 = int(0.9*len(text))\n",
    "\n",
    "Xtr = text[:n1]\n",
    "Ytr = labels[:n1]\n",
    "Xdev = text[n1:n2]\n",
    "Ydev = labels[n1:n2]\n",
    "Xte = text[n2:]\n",
    "Yte = labels[n2:]\n",
    "\n",
    "print(Xtr.shape, Ytr.shape)\n",
    "print(Xdev.shape, Ydev.shape)\n",
    "print(Xte.shape, Yte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ba629f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoads(Dataset):\n",
    "    \n",
    "    def __init__(self, X, Y):\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # inputs to the transformer\n",
    "        X = torch.tensor(self.x[idx])\n",
    "        Y = torch.tensor(self.y[idx])\n",
    "        mask = torch.ones(len(self.x[0])).float()\n",
    "        \n",
    "        return X, Y, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab177d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataLoads(Xtr, Ytr)\n",
    "dev_dataset = DataLoads(Xdev, Ydev)\n",
    "test_dataset = DataLoads(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1e94e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a GPT instance\n",
    "from minigpt.model import GPT\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt-nano'\n",
    "model_config.vocab_size = train_dataset.get_vocab_size()\n",
    "model_config.block_size = 500\n",
    "model = GPT(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe91c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Trainer object\n",
    "from minigpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-4 # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 2000\n",
    "train_config.num_workers = 0\n",
    "trainer = Trainer(train_config, model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a180fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_end_callback(trainer):\n",
    "    if trainer.iter_num % 100 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "\n",
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
